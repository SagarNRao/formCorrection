{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09dee971",
   "metadata": {},
   "source": [
    "# MediaPipe Pose Visualization for All Exercises\n",
    "\n",
    "This notebook processes all video files in the `exercises/` folder and displays the MediaPipe stick figure overlays to verify pose detection quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bb13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from IPython import display as ipydisplay\n",
    "import time\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc55a59",
   "metadata": {},
   "source": [
    "## Visualize MediaPipe Stick Figures for All Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a2b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ Visualization complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def visualize_all_exercises(folder='exercises', skip_frames=2, max_frames_per_video=100):\n",
    "    \"\"\"\n",
    "    Process all videos in the exercises folder and display MediaPipe stick figures.\n",
    "    \n",
    "    Args:\n",
    "        folder: path to exercises folder\n",
    "        skip_frames: process every Nth frame (higher = faster but less smooth)\n",
    "        max_frames_per_video: maximum frames to show per video (prevents very long displays)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Folder '{folder}' not found. Please create it and add exercise videos.\")\n",
    "        return\n",
    "    \n",
    "    # Find all video files\n",
    "    video_files = []\n",
    "    for ext in ['*.mp4', '*.avi', '*.mov', '*.MP4', '*.AVI', '*.MOV']:\n",
    "        video_files.extend(glob.glob(os.path.join(folder, ext)))\n",
    "    \n",
    "    if not video_files:\n",
    "        print(f\"No video files found in '{folder}/'\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(video_files)} video(s): {[os.path.basename(f) for f in video_files]}\")\n",
    "    print()\n",
    "    \n",
    "    # Initialize MediaPipe Pose\n",
    "    pose = mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        smooth_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    \n",
    "    # Create display handle for updating the same output\n",
    "    display_handle = ipydisplay.display(ipydisplay.Image(data=b''), display_id=True)\n",
    "    \n",
    "    try:\n",
    "        for video_path in video_files:\n",
    "            video_name = os.path.basename(video_path)\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Processing: {video_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"  ‚ùå Failed to open {video_name}\")\n",
    "                continue\n",
    "            \n",
    "            fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            print(f\"  üìπ FPS: {fps:.1f} | Total frames: {total_frames}\")\n",
    "            \n",
    "            frame_count = 0\n",
    "            processed_count = 0\n",
    "            detected_count = 0\n",
    "            \n",
    "            while cap.isOpened() and processed_count < max_frames_per_video:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Skip frames for performance\n",
    "                if frame_count % (skip_frames + 1) != 0:\n",
    "                    frame_count += 1\n",
    "                    continue\n",
    "                \n",
    "                frame_count += 1\n",
    "                processed_count += 1\n",
    "                \n",
    "                # Convert to RGB for MediaPipe\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(rgb_frame)\n",
    "                \n",
    "                # Draw pose landmarks on the frame\n",
    "                annotated_frame = frame.copy()\n",
    "                \n",
    "                if results.pose_landmarks:\n",
    "                    detected_count += 1\n",
    "                    \n",
    "                    # Draw landmarks and connections\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        annotated_frame,\n",
    "                        results.pose_landmarks,\n",
    "                        mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "                    )\n",
    "                    \n",
    "                    # Add status text\n",
    "                    cv2.putText(\n",
    "                        annotated_frame,\n",
    "                        f\"Frame {frame_count}/{total_frames} - POSE DETECTED\",\n",
    "                        (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        (0, 255, 0),\n",
    "                        2\n",
    "                    )\n",
    "                else:\n",
    "                    # No pose detected\n",
    "                    cv2.putText(\n",
    "                        annotated_frame,\n",
    "                        f\"Frame {frame_count}/{total_frames} - NO POSE\",\n",
    "                        (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        (0, 0, 255),\n",
    "                        2\n",
    "                    )\n",
    "                \n",
    "                # Add video name\n",
    "                cv2.putText(\n",
    "                    annotated_frame,\n",
    "                    video_name,\n",
    "                    (10, annotated_frame.shape[0] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    (255, 255, 255),\n",
    "                    2\n",
    "                )\n",
    "                \n",
    "                # Encode and display\n",
    "                _, buffer = cv2.imencode('.jpg', annotated_frame, [int(cv2.IMWRITE_JPEG_QUALITY), 85])\n",
    "                display_handle.update(ipydisplay.Image(data=buffer.tobytes()))\n",
    "                \n",
    "                # Small delay for visualization (adjust as needed)\n",
    "                time.sleep(0.05)\n",
    "            \n",
    "            cap.release()\n",
    "            \n",
    "            detection_rate = (detected_count / processed_count * 100) if processed_count > 0 else 0\n",
    "            print(f\"  ‚úÖ Processed {processed_count} frames | Pose detected in {detected_count} ({detection_rate:.1f}%)\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è  Visualization interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        pose.close()\n",
    "        ipydisplay.clear_output(wait=True)\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úÖ Visualization complete!\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "# Run visualization\n",
    "visualize_all_exercises(folder='exercises', skip_frames=2, max_frames_per_video=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a9857",
   "metadata": {},
   "source": [
    "## Visualize with Stick Figure Only (No Original Video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77227b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_stick_figures_only(folder='exercises', skip_frames=2, max_frames_per_video=100):\n",
    "    \"\"\"\n",
    "    Show only the stick figure skeleton on a black background (no original video).\n",
    "    Useful for focusing on the pose structure.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Folder '{folder}' not found.\")\n",
    "        return\n",
    "    \n",
    "    video_files = []\n",
    "    for ext in ['*.mp4', '*.avi', '*.mov', '*.MP4', '*.AVI', '*.MOV']:\n",
    "        video_files.extend(glob.glob(os.path.join(folder, ext)))\n",
    "    \n",
    "    if not video_files:\n",
    "        print(f\"No videos found in '{folder}/'\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(video_files)} video(s)\")\n",
    "    \n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1)\n",
    "    display_handle = ipydisplay.display(ipydisplay.Image(data=b''), display_id=True)\n",
    "    \n",
    "    try:\n",
    "        for video_path in video_files:\n",
    "            video_name = os.path.basename(video_path)\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Processing: {video_name} (stick figure only)\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                continue\n",
    "            \n",
    "            frame_count = 0\n",
    "            processed_count = 0\n",
    "            \n",
    "            # Get frame dimensions from first frame\n",
    "            ret, first_frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            h, w = first_frame.shape[:2]\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset to start\n",
    "            \n",
    "            while cap.isOpened() and processed_count < max_frames_per_video:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                if frame_count % (skip_frames + 1) != 0:\n",
    "                    frame_count += 1\n",
    "                    continue\n",
    "                \n",
    "                frame_count += 1\n",
    "                processed_count += 1\n",
    "                \n",
    "                # Process with MediaPipe\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(rgb_frame)\n",
    "                \n",
    "                # Create black canvas\n",
    "                canvas = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "                \n",
    "                if results.pose_landmarks:\n",
    "                    # Draw stick figure on black background\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        canvas,\n",
    "                        results.pose_landmarks,\n",
    "                        mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=3),\n",
    "                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "                    )\n",
    "                    status_color = (0, 255, 0)\n",
    "                    status_text = \"POSE DETECTED\"\n",
    "                else:\n",
    "                    status_color = (0, 0, 255)\n",
    "                    status_text = \"NO POSE\"\n",
    "                \n",
    "                # Add info text\n",
    "                cv2.putText(canvas, f\"Frame {frame_count} - {status_text}\", (10, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)\n",
    "                cv2.putText(canvas, video_name, (10, h - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                _, buffer = cv2.imencode('.jpg', canvas, [int(cv2.IMWRITE_JPEG_QUALITY), 85])\n",
    "                display_handle.update(ipydisplay.Image(data=buffer.tobytes()))\n",
    "                time.sleep(0.05)\n",
    "            \n",
    "            cap.release()\n",
    "            print(f\"  ‚úÖ Processed {processed_count} frames\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è  Interrupted\")\n",
    "    finally:\n",
    "        pose.close()\n",
    "        ipydisplay.clear_output(wait=True)\n",
    "        print(\"\\n‚úÖ Complete!\")\n",
    "\n",
    "# Uncomment to run stick-figure-only visualization:\n",
    "visualize_stick_figures_only(folder='exercises', skip_frames=2, max_frames_per_video=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb4c25",
   "metadata": {},
   "source": [
    "## Compare Side-by-Side: Original + Stick Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50585bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_side_by_side(folder='exercises', skip_frames=2, max_frames_per_video=100):\n",
    "    \"\"\"\n",
    "    Show original video frame and stick figure side by side.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Folder '{folder}' not found.\")\n",
    "        return\n",
    "    \n",
    "    video_files = []\n",
    "    for ext in ['*.mp4', '*.avi', '*.mov', '*.MP4', '*.AVI', '*.MOV']:\n",
    "        video_files.extend(glob.glob(os.path.join(folder, ext)))\n",
    "    \n",
    "    if not video_files:\n",
    "        print(f\"No videos found.\")\n",
    "        return\n",
    "    \n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1)\n",
    "    display_handle = ipydisplay.display(ipydisplay.Image(data=b''), display_id=True)\n",
    "    \n",
    "    try:\n",
    "        for video_path in video_files:\n",
    "            video_name = os.path.basename(video_path)\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Side-by-Side: {video_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                continue\n",
    "            \n",
    "            frame_count = 0\n",
    "            processed_count = 0\n",
    "            \n",
    "            while cap.isOpened() and processed_count < max_frames_per_video:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                if frame_count % (skip_frames + 1) != 0:\n",
    "                    frame_count += 1\n",
    "                    continue\n",
    "                \n",
    "                frame_count += 1\n",
    "                processed_count += 1\n",
    "                \n",
    "                h, w = frame.shape[:2]\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(rgb_frame)\n",
    "                \n",
    "                # Left: original with overlay\n",
    "                left = frame.copy()\n",
    "                # Right: stick figure on black\n",
    "                right = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "                \n",
    "                if results.pose_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        left, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "                    )\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        right, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=3),\n",
    "                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)\n",
    "                    )\n",
    "                \n",
    "                # Combine side by side\n",
    "                combined = np.hstack([left, right])\n",
    "                \n",
    "                # Add labels\n",
    "                cv2.putText(combined, \"Original + Overlay\", (10, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(combined, \"Stick Figure Only\", (w + 10, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(combined, f\"Frame {frame_count}\", (10, h - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                _, buffer = cv2.imencode('.jpg', combined, [int(cv2.IMWRITE_JPEG_QUALITY), 85])\n",
    "                display_handle.update(ipydisplay.Image(data=buffer.tobytes()))\n",
    "                time.sleep(0.05)\n",
    "            \n",
    "            cap.release()\n",
    "            print(f\"  ‚úÖ Processed {processed_count} frames\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è  Interrupted\")\n",
    "    finally:\n",
    "        pose.close()\n",
    "        ipydisplay.clear_output(wait=True)\n",
    "        print(\"\\n‚úÖ Complete!\")\n",
    "\n",
    "# Uncomment to run side-by-side visualization:\n",
    "# visualize_side_by_side(folder='exercises', skip_frames=2, max_frames_per_video=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
