{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose-Based Form Checker\n",
    "\n",
    "Uses **pre-recorded exercise videos** to generate reference animations.\n",
    "User performs in front of webcam → live feedback via stick figures (blue = reference, green/red = user).\n",
    "Streamed to phone via Flask.\n",
    "\n",
    "**Folder structure:**\n",
    "```\n",
    "project/\n",
    "├── recordFromVideo.ipynb\n",
    "└── exercises/\n",
    "    ├── squat.mp4\n",
    "    ├── pushup.mp4\n",
    "    └── dumbbell_curls.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from flask import Flask, Response\n",
    "import threading\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Global frame for streaming\n",
    "current_frame = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper: Calculate Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ab = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc) + 1e-6)\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Reference from Video (Instead of Recording Yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reference_from_video(video_path: str, exercise_name: str, target_fps: float = 10.0):\n",
    "    \"\"\"\n",
    "    Extracts pose landmarks from a pre-recorded video and saves as .pkl\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video not found: {video_path}\")\n",
    "        return\n",
    "\n",
    "    pose = mp_pose.Pose(static_image_mode=False,\n",
    "                        model_complexity=1,\n",
    "                        enable_segmentation=False,\n",
    "                        min_detection_confidence=0.5,\n",
    "                        min_tracking_confidence=0.5)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = max(1, int(video_fps / target_fps))\n",
    "    references = []\n",
    "    frame_count = 0\n",
    "\n",
    "    print(f\"Extracting reference from {video_path} @ ~{target_fps} FPS...\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(rgb)\n",
    "\n",
    "            if results.pose_landmarks:\n",
    "                lm_list = [(lm.x, lm.y, lm.z, lm.visibility) for lm in results.pose_landmarks.landmark]\n",
    "                references.append(lm_list)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    pose.close()\n",
    "\n",
    "    # Save\n",
    "    pkl_path = f\"{exercise_name}.pkl\"\n",
    "    with open(pkl_path, 'wb') as f:\n",
    "        pickle.dump(references, f)\n",
    "\n",
    "    print(f\"Saved {len(references)} reference frames → {pkl_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Discover & Extract All Videos in `exercises/` Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_references_from_folder(folder='exercises', target_fps=10.0):\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Folder '{folder}' not found!\")\n",
    "        return\n",
    "\n",
    "    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv']\n",
    "    video_files = []\n",
    "    for ext in video_extensions:\n",
    "        video_files.extend(glob.glob(os.path.join(folder, ext)))\n",
    "\n",
    "    if not video_files:\n",
    "        print(\"No videos found in exercises/ folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(video_files)} video(s). Extracting references...\\n\")\n",
    "    for video_path in video_files:\n",
    "        name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        extract_reference_from_video(video_path, name, target_fps)\n",
    "    print(\"\\nAll references extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run This Once: Extract All References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 video(s). Extracting references...\n",
      "\n",
      "Extracting reference from exercises\\deadlift.mp4 @ ~10.0 FPS...\n",
      "Saved 35 reference frames → deadlift.pkl\n",
      "Extracting reference from exercises\\plank.mp4 @ ~10.0 FPS...\n",
      "Saved 39 reference frames → plank.pkl\n",
      "Extracting reference from exercises\\push-up.mp4 @ ~10.0 FPS...\n",
      "Saved 75 reference frames → push-up.pkl\n",
      "Extracting reference from exercises\\romanian_deadlift.mp4 @ ~10.0 FPS...\n",
      "Saved 27 reference frames → romanian_deadlift.pkl\n",
      "Extracting reference from exercises\\squat.mp4 @ ~10.0 FPS...\n",
      "Saved 51 reference frames → squat.pkl\n",
      "\n",
      "All references extracted!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to process all videos in exercises/\n",
    "extract_all_references_from_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Exercise (Live Feedback + Streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_exercise(exercise_name):\n",
    "    global current_frame\n",
    "    \n",
    "    pkl_path = f\"{exercise_name}.pkl\"\n",
    "    if not os.path.exists(pkl_path):\n",
    "        print(f\"Reference not found: {pkl_path}. Run extraction first!\")\n",
    "        return\n",
    "\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        reference_sequence = pickle.load(f)\n",
    "    \n",
    "    if not reference_sequence:\n",
    "        print(\"Empty reference sequence.\")\n",
    "        return\n",
    "\n",
    "    pose = mp_pose.Pose()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    ref_index = 0\n",
    "    animation_fps = 10\n",
    "    frame_delay = 1.0 / animation_fps\n",
    "    last_ref_time = time.time()\n",
    "    angle_threshold = 20\n",
    "    \n",
    "    pose_connections = mp_pose.POSE_CONNECTIONS\n",
    "    \n",
    "    print(f\"Starting {exercise_name}. Match the BLUE stick figure.\")\n",
    "    print(f\"Stream: http://[YOUR-PC-IP]:5000/video  |  Press 'q' to quit.\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb)\n",
    "        \n",
    "        black = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Draw reference (BLUE)\n",
    "        ref_lm = reference_sequence[ref_index]\n",
    "        for conn in pose_connections:\n",
    "            start, end = ref_lm[conn[0]], ref_lm[conn[1]]\n",
    "            if start[3] > 0.1 and end[3] > 0.1:\n",
    "                cv2.line(black,\n",
    "                         (int(start[0] * width), int(start[1] * height)),\n",
    "                         (int(end[0] * width), int(end[1] * height)),\n",
    "                         (255, 0, 0), 2)  # BGR Blue\n",
    "        \n",
    "        # Draw user (GREEN if correct, RED if wrong)\n",
    "        if results.pose_landmarks:\n",
    "            user_lm = [(lm.x, lm.y, lm.z, lm.visibility) for lm in results.pose_landmarks.landmark]\n",
    "            \n",
    "            for conn in pose_connections:\n",
    "                i1, i2 = conn\n",
    "                r1, r2 = ref_lm[i1], ref_lm[i2]\n",
    "                u1, u2 = user_lm[i1], user_lm[i2]\n",
    "                \n",
    "                if all(x[3] > 0.1 for x in [r1, r2, u1, u2]):\n",
    "                    # Find parent joint for angle\n",
    "                    parent_idx = None\n",
    "                    for c in pose_connections:\n",
    "                        if c[1] == i2 and c[0] != i1:\n",
    "                            parent_idx = c[0]; break\n",
    "                        if c[0] == i2 and c[1] != i1:\n",
    "                            parent_idx = c[1]; break\n",
    "                    \n",
    "                    if parent_idx is not None and ref_lm[parent_idx][3] > 0.1 and user_lm[parent_idx][3] > 0.1:\n",
    "                        rp, up = ref_lm[parent_idx], user_lm[parent_idx]\n",
    "                        \n",
    "                        ref_angle = calculate_angle((r1[0], r1[1]), (r2[0], r2[1]), (rp[0], rp[1]))\n",
    "                        user_angle = calculate_angle((u1[0], u1[1]), (u2[0], u2[1]), (up[0], up[1]))\n",
    "                        \n",
    "                        color = (0, 255, 0) if abs(ref_angle - user_angle) < angle_threshold else (0, 0, 255)\n",
    "                        \n",
    "                        cv2.line(black,\n",
    "                                 (int(u1[0] * width), int(u1[1] * height)),\n",
    "                                 (int(u2[0] * width), int(u2[1] * height)),\n",
    "                                 color, 2)\n",
    "        \n",
    "        # Update stream\n",
    "        current_frame = cv2.imencode('.jpg', black)[1].tobytes()\n",
    "        \n",
    "        # Advance reference\n",
    "        if time.time() - last_ref_time >= frame_delay:\n",
    "            last_ref_time = time.time()\n",
    "            ref_index = (ref_index + 1) % len(reference_sequence)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Streaming Server (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming server running on http://[YOUR-PC-IP]:5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.16.194.71:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return '<html><body><h2>Workout Stream</h2><img src=\"/video\" width=\"100%\"></body></html>'\n",
    "\n",
    "def gen():\n",
    "    global current_frame\n",
    "    while True:\n",
    "        if current_frame is not None:\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + current_frame + b'\\r\\n')\n",
    "        time.sleep(0.01)\n",
    "\n",
    "@app.route('/video')\n",
    "def video_feed():\n",
    "    return Response(gen(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "def run_server():\n",
    "    app.run(host='0.0.0.0', port=5000, threaded=True, use_reloader=False)\n",
    "\n",
    "# Start in background\n",
    "thread = threading.Thread(target=run_server, daemon=True)\n",
    "thread.start()\n",
    "print(\"Streaming server running on http://[YOUR-PC-IP]:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Any Exercise\n",
    "\n",
    "Just type the **exact filename (without extension)** from `exercises/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting squat. Match the BLUE stick figure.\n",
      "Stream: http://[YOUR-PC-IP]:5000/video  |  Press 'q' to quit.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example: perform_exercise('squat')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# perform_exercise('pushup')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# perform_exercise('dumbbell_curls')\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mperform_exercise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msquat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Change this to your video name\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 89\u001b[0m, in \u001b[0;36mperform_exercise\u001b[1;34m(exercise_name)\u001b[0m\n\u001b[0;32m     86\u001b[0m         last_ref_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     87\u001b[0m         ref_index \u001b[38;5;241m=\u001b[39m (ref_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(reference_sequence)\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     92\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example: perform_exercise('squat')\n",
    "# perform_exercise('pushup')\n",
    "# perform_exercise('dumbbell_curls')\n",
    "\n",
    "perform_exercise('squat')  # Change this to your video name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
