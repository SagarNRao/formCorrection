{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pose-Based Form Checker (RTSP Stream) – **IPython Real-Time Display**\n",
        "\n",
        "*Reference animations from pre-recorded videos.*  \n",
        "*Live RTSP video (laptop → OBS/FFmpeg) → pose detection → **blue = reference, green/red = user**.*  \n",
        "*Real-time feedback **inside the notebook** using `IPython.display` + JPEG streaming (no Flask, no external browser).*\n",
        "\n",
        "---\n",
        "\n",
        "## Setup\n",
        "\n",
        "1. **Start RTSP on laptop** (low-latency):\n",
        "   ```bash\n",
        "   ffmpeg -f dshow -i video=\"YOUR_WEBCAM_NAME\" -c:v libx264 -preset ultrafast -tune zerolatency -profile:v baseline -pix_fmt yuv420p -maxrate 1000k -bufsize 2000k -g 30 -f rtsp rtsp://0.0.0.0:8554/webcam.sdp\n",
        "   ```\n",
        "\n",
        "2. **Update `RTSP_URL`** if your laptop IP changes.\n",
        "\n",
        "3. Run the notebook – the live stick-figure overlay appears **right below**.\n",
        "\n",
        "---\n",
        "\n",
        "**Folder structure**\n",
        "```\n",
        "project/\n",
        "├── this_notebook.ipynb\n",
        "└── exercises/\n",
        "    ├── squat.mp4\n",
        "    ├── push-up.mp4\n",
        "    └── ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "from IPython import display as ipydisplay\n",
        "\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# RTSP configuration\n",
        "# ----------------------------------------------------\n",
        "RTSP_URL = \"rtsp://10.227.207.170:8554/webcam.sdp\"   # <-- change if needed\n",
        "\n",
        "# Improved FFmpeg options to handle stream errors gracefully\n",
        "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = (\n",
        "    \"rtsp_transport;tcp|\"           # force TCP\n",
        "    \"fflags;nobuffer+discardcorrupt|\"  # discard corrupted frames\n",
        "    \"flags;low_delay|\"              # low-delay decoding\n",
        "    \"max_delay;0|\"                  # zero delay\n",
        "    \"err_detect;ignore_err\"         # ignore decode errors\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper: angle calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_angle(a, b, c):\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "    c = np.array(c)\n",
        "    ab = a - b\n",
        "    bc = c - b\n",
        "    cosine_angle = np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc) + 1e-6)\n",
        "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
        "    return np.degrees(angle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract reference landmarks from a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_reference_from_video(video_path: str, exercise_name: str, target_fps: float = 10.0):\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"Video not found: {video_path}\")\n",
        "        return\n",
        "\n",
        "    pose = mp_pose.Pose(static_image_mode=False,\n",
        "                        model_complexity=1,\n",
        "                        enable_segmentation=False,\n",
        "                        min_detection_confidence=0.5,\n",
        "                        min_tracking_confidence=0.5)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Cannot open video: {video_path}\")\n",
        "        return\n",
        "\n",
        "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_interval = max(1, int(video_fps / target_fps))\n",
        "    references = []\n",
        "    frame_count = 0\n",
        "\n",
        "    print(f\"Extracting reference from {video_path} @ ~{target_fps} FPS...\")\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_count % frame_interval == 0:\n",
        "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = pose.process(rgb)\n",
        "            if results.pose_landmarks:\n",
        "                lm_list = [(lm.x, lm.y, lm.z, lm.visibility) for lm in results.pose_landmarks.landmark]\n",
        "                references.append(lm_list)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    pose.close()\n",
        "\n",
        "    pkl_path = f\"{exercise_name}.pkl\"\n",
        "    with open(pkl_path, 'wb') as f:\n",
        "        pickle.dump(references, f)\n",
        "\n",
        "    print(f\"Saved {len(references)} reference frames → {pkl_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Auto-extract **all** videos in `exercises/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_all_references_from_folder(folder='exercises', target_fps=10.0):\n",
        "    if not os.path.exists(folder):\n",
        "        print(f\"Folder '{folder}' not found!\")\n",
        "        return\n",
        "\n",
        "    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv']\n",
        "    video_files = []\n",
        "    for ext in video_extensions:\n",
        "        video_files.extend(glob.glob(os.path.join(folder, ext)))\n",
        "\n",
        "    if not video_files:\n",
        "        print(\"No videos found in exercises/ folder.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_files)} video(s). Extracting references...\\n\")\n",
        "    for video_path in video_files:\n",
        "        name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "        extract_reference_from_video(video_path, name, target_fps)\n",
        "    print(\"\\nAll references extracted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run **once** – extract every reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_all_references_from_folder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Live pose comparison **with IPython real-time display**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_exercise(exercise_name: str):\n",
        "    pkl_path = f\"{exercise_name}.pkl\"\n",
        "    if not os.path.exists(pkl_path):\n",
        "        print(f\"Reference not found: {pkl_path}. Run extraction first!\")\n",
        "        return\n",
        "\n",
        "    with open(pkl_path, 'rb') as f:\n",
        "        reference_sequence = pickle.load(f)\n",
        "    if not reference_sequence:\n",
        "        print(\"Empty reference sequence.\")\n",
        "        return\n",
        "\n",
        "    pose = mp_pose.Pose()\n",
        "\n",
        "    # ---------- RTSP capture (fallback to GStreamer) ----------\n",
        "    print(\"Connecting to RTSP stream...\")\n",
        "    cap = cv2.VideoCapture(RTSP_URL, cv2.CAP_FFMPEG)\n",
        "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"FFmpeg failed → trying GStreamer...\")\n",
        "        gst = (\n",
        "            f\"rtspsrc location={RTSP_URL} latency=0 protocols=tcp ! \"\n",
        "            \"rtph264depay ! h264parse ! avdec_h264 ! \"\n",
        "            \"videoconvert ! video/x-raw,format=BGR ! appsink drop=1\"\n",
        "        )\n",
        "        cap = cv2.VideoCapture(gst, cv2.CAP_GSTREAMER)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"ERROR: Cannot open {RTSP_URL}\")\n",
        "        return\n",
        "\n",
        "    print(\"Connected! Starting live display...\")\n",
        "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "    # ---------- IPython display placeholder ----------\n",
        "    display_handle = ipydisplay.display(ipydisplay.Image(data=b''), display_id=True)\n",
        "\n",
        "    # ---------- Animation control ----------\n",
        "    ref_idx = 0\n",
        "    anim_fps = 10\n",
        "    frame_delay = 1.0 / anim_fps\n",
        "    last_ref_time = time.time()\n",
        "    angle_thr = 20\n",
        "\n",
        "    pose_connections = mp_pose.POSE_CONNECTIONS\n",
        "\n",
        "    frame_cnt = 0\n",
        "    err_cnt = 0\n",
        "    max_err = 10\n",
        "\n",
        "    try:\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                err_cnt += 1\n",
        "                if err_cnt >= max_err:\n",
        "                    print(\"Too many dropped frames → stopping.\")\n",
        "                    break\n",
        "                time.sleep(0.1)\n",
        "                continue\n",
        "            err_cnt = 0\n",
        "            frame_cnt += 1\n",
        "\n",
        "            # Process every 2nd frame to reduce CPU load\n",
        "            if frame_cnt % 2 != 0:\n",
        "                continue\n",
        "\n",
        "            h, w, _ = frame.shape\n",
        "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = pose.process(rgb)\n",
        "\n",
        "            # Blank canvas\n",
        "            canvas = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "\n",
        "            # ----- Draw REFERENCE (BLUE) -----\n",
        "            ref_lm = reference_sequence[ref_idx]\n",
        "            for conn in pose_connections:\n",
        "                s, e = ref_lm[conn[0]], ref_lm[conn[1]]\n",
        "                if s[3] > 0.1 and e[3] > 0.1:\n",
        "                    cv2.line(canvas,\n",
        "                             (int(s[0] * w), int(s[1] * h)),\n",
        "                             (int(e[0] * w), int(e[1] * h)),\n",
        "                             (255, 0, 0), 2)   # BGR blue\n",
        "\n",
        "            # ----- Draw USER (GREEN / RED) -----\n",
        "            if results.pose_landmarks:\n",
        "                user_lm = [(lm.x, lm.y, lm.z, lm.visibility) for lm in results.pose_landmarks.landmark]\n",
        "                for conn in pose_connections:\n",
        "                    i1, i2 = conn\n",
        "                    r1, r2 = ref_lm[i1], ref_lm[i2]\n",
        "                    u1, u2 = user_lm[i1], user_lm[i2]\n",
        "\n",
        "                    if all(x[3] > 0.1 for x in [r1, r2, u1, u2]):\n",
        "                        parent_idx = None\n",
        "                        for c in pose_connections:\n",
        "                            if c[1] == i2 and c[0] != i1:\n",
        "                                parent_idx = c[0]; break\n",
        "                            if c[0] == i2 and c[1] != i1:\n",
        "                                parent_idx = c[1]; break\n",
        "                        if parent_idx is not None and ref_lm[parent_idx][3] > 0.1 and user_lm[parent_idx][3] > 0.1:\n",
        "                            rp, up = ref_lm[parent_idx], user_lm[parent_idx]\n",
        "                            ref_ang = calculate_angle((r1[0], r1[1]), (r2[0], r2[1]), (rp[0], rp[1]))\n",
        "                            usr_ang = calculate_angle((u1[0], u1[1]), (u2[0], u2[1]), (up[0], up[1]))\n",
        "                            color = (0, 255, 0) if abs(ref_ang - usr_ang) < angle_thr else (0, 0, 255)\n",
        "                            cv2.line(canvas,\n",
        "                                     (int(u1[0] * w), int(u1[1] * h)),\n",
        "                                     (int(u2[0] * w), int(u2[1] * h)),\n",
        "                                     color, 2)\n",
        "\n",
        "            # ----- Encode to JPEG and update display -----\n",
        "            _, buffer = cv2.imencode('.jpeg', canvas)\n",
        "            jpeg_data = buffer.tobytes()\n",
        "            display_handle.update(ipydisplay.Image(data=jpeg_data))\n",
        "\n",
        "            # ----- Advance reference animation -----\n",
        "            if time.time() - last_ref_time >= frame_delay:\n",
        "                last_ref_time = time.time()\n",
        "                ref_idx = (ref_idx + 1) % len(reference_sequence)\n",
        "\n",
        "            time.sleep(0.01)  # Prevent 100% CPU\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nStream stopped by user.\")\n",
        "    finally:\n",
        "        cap.release()\n",
        "        ipydisplay.clear_output()\n",
        "        print(\"Cleanup complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Start a workout (filename **without** extension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examples:\n",
        "# perform_exercise('squat')\n",
        "# perform_exercise('push-up')\n",
        "# perform_exercise('romanian_deadlift')\n",
        "\n",
        "perform_exercise('romanian_deadlift')   # change to your exercise"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
