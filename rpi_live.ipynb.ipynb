{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b9b0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup complete\n"
     ]
    }
   ],
   "source": [
    "# --- 2_RPi_MediaPipe_Client.ipynb ---\n",
    "# Run this on your Raspberry Pi 4B\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "from IPython import display as ipydisplay\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "RTSP_URL = \"rtsp://10.227.207.170:8554/webcam.sdp\"   # ← Laptop stream\n",
    "EXERCISE_NAME = \"romanian_deadlift\"                 # Change as needed\n",
    "# -------------------------------------------\n",
    "\n",
    "# Optimize OpenCV for RTSP\n",
    "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = (\n",
    "    \"rtsp_transport;tcp|\"\n",
    "    \"fflags;nobuffer+discardcorrupt|\"\n",
    "    \"flags;low_delay|\"\n",
    "    \"max_delay;0|\"\n",
    "    \"err_detect;ignore_err\"\n",
    ")\n",
    "\n",
    "# Load reference pose sequence\n",
    "pkl_path = f\"{EXERCISE_NAME}.pkl\"\n",
    "if not os.path.exists(pkl_path):\n",
    "    raise FileNotFoundError(f\"Reference not found: {pkl_path}. Run extraction first!\")\n",
    "\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    reference_sequence = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(reference_sequence)} reference frames from {pkl_path}\")\n",
    "\n",
    "# Try GStreamer with hardware decode (recommended)\n",
    "gst_pipeline = (\n",
    "    f\"rtspsrc location={RTSP_URL} latency=200 protocols=tcp ! \"\n",
    "    \"rtph264depay ! h264parse ! v4l2h264dec ! \"\n",
    "    \"videoconvert ! video/x-raw,format=BGR,width=640,height=480,framerate=15/1 ! \"\n",
    "    \"appsink drop=1 max-buffers=1\"\n",
    ")\n",
    "\n",
    "print(\"Connecting to stream...\")\n",
    "cap = cv2.VideoCapture(gst_pipeline, cv2.CAP_GSTREAMER)\n",
    "\n",
    "# Fallback to FFmpeg\n",
    "if not cap.isOpened():\n",
    "    print(\"GStreamer failed → trying FFmpeg...\")\n",
    "    cap = cv2.VideoCapture(RTSP_URL, cv2.CAP_FFMPEG)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise ConnectionError(f\"Cannot connect to {RTSP_URL}\")\n",
    "\n",
    "print(\"Connected! Starting live pose overlay...\")\n",
    "\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# IPython display\n",
    "display_handle = ipydisplay.display(ipydisplay.Image(data=b''), display_id=True)\n",
    "\n",
    "# Animation control\n",
    "ref_idx = 0\n",
    "anim_fps = 10\n",
    "frame_delay = 1.0 / anim_fps\n",
    "last_ref_time = time.time()\n",
    "angle_thr = 20\n",
    "frame_cnt = 0\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a); b = np.array(b); c = np.array(c)\n",
    "    ab = a - b; bc = c - b\n",
    "    cosine = np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc) + 1e-6)\n",
    "    angle = np.arccos(np.clip(cosine, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        # Process every 3rd frame (~10 FPS)\n",
    "        if frame_cnt % 3 != 0:\n",
    "            frame_cnt += 1\n",
    "            continue\n",
    "        frame_cnt += 1\n",
    "\n",
    "        h, w, _ = frame.shape\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb)\n",
    "\n",
    "        canvas = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        # --- Draw REFERENCE (BLUE) ---\n",
    "        ref_lm = reference_sequence[ref_idx]\n",
    "        for a, b in mp_pose.POSE_CONNECTIONS:\n",
    "            s, e = ref_lm[a], ref_lm[b]\n",
    "            if s[3] > 0.1 and e[3] > 0.1:\n",
    "                cv2.line(canvas,\n",
    "                         (int(s[0]*w), int(s[1]*h)),\n",
    "                         (int(e[0]*w), int(e[1]*h)),\n",
    "                         (255, 0, 0), 2)  # Blue\n",
    "\n",
    "        # --- Draw USER (GREEN/RED) ---\n",
    "        if results.pose_landmarks:\n",
    "            user_lm = [(lm.x, lm.y, lm.z, lm.visibility) for lm in results.pose_landmarks.landmark]\n",
    "            for a, b in mp_pose.POSE_CONNECTIONS:\n",
    "                r1, r2 = ref_lm[a], ref_lm[b]\n",
    "                u1, u2 = user_lm[a], user_lm[b]\n",
    "                if all(x[3] > 0.1 for x in [r1, r2, u1, u2]):\n",
    "                    # Find parent joint\n",
    "                    parent = None\n",
    "                    for conn in mp_pose.POSE_CONNECTIONS:\n",
    "                        if conn[1] == b:\n",
    "                            parent = conn[0]\n",
    "                            break\n",
    "                    if parent is not None:\n",
    "                        rp = ref_lm[parent]\n",
    "                        up = user_lm[parent]\n",
    "                        if rp[3] > 0.1 and up[3] > 0.1:\n",
    "                            ref_ang = calculate_angle((r1[0], r1[1]), (r2[0], r2[1]), (rp[0], rp[1]))\n",
    "                            usr_ang = calculate_angle((u1[0], u1[1]), (u2[0], u2[1]), (up[0], up[1]))\n",
    "                            color = (0, 255, 0) if abs(ref_ang - usr_ang) < angle_thr else (0, 0, 255)\n",
    "                            cv2.line(canvas,\n",
    "                                     (int(u1[0]*w), int(u1[1]*h)),\n",
    "                                     (int(u2[0]*w), int(u2[1]*h)),\n",
    "                                     color, 2)\n",
    "\n",
    "        # --- Update display ---\n",
    "        _, buf = cv2.imencode('.jpeg', canvas, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
    "        display_handle.update(ipydisplay.Image(data=buf.tobytes()))\n",
    "\n",
    "        # --- Advance reference ---\n",
    "        if time.time() - last_ref_time >= frame_delay:\n",
    "            last_ref_time = time.time()\n",
    "            ref_idx = (ref_idx + 1) % len(reference_sequence)\n",
    "\n",
    "        time.sleep(0.01)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    pose.close()\n",
    "    ipydisplay.clear_output()\n",
    "    print(\"Cleanup complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
